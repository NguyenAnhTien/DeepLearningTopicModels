{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "#from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "os.chdir('/home/ekhongl/Codes/DL - Topic Modelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_src = os.path.join(os.getcwd(), 'data/raw_20news/20news-18828')\n",
    "\n",
    "dir_src_classes = list( map(lambda x: os.path.join(dir_src, x ), os.listdir(dir_src)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently loading the following topic (iteration 0):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/alt.atheism\n",
      "Currently loading the following topic (iteration 1):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/comp.graphics\n",
      "Currently loading the following topic (iteration 2):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/comp.os.ms-windows.misc\n",
      "Currently loading the following topic (iteration 3):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/comp.sys.ibm.pc.hardware\n",
      "Currently loading the following topic (iteration 4):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/comp.sys.mac.hardware\n",
      "Currently loading the following topic (iteration 5):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/comp.windows.x\n",
      "Currently loading the following topic (iteration 6):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/misc.forsale\n",
      "Currently loading the following topic (iteration 7):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/rec.autos\n",
      "Currently loading the following topic (iteration 8):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/rec.motorcycles\n",
      "Currently loading the following topic (iteration 9):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/rec.sport.baseball\n",
      "Currently loading the following topic (iteration 10):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/rec.sport.hockey\n",
      "Currently loading the following topic (iteration 11):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/sci.crypt\n",
      "Currently loading the following topic (iteration 12):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/sci.electronics\n",
      "Currently loading the following topic (iteration 13):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/sci.med\n",
      "Currently loading the following topic (iteration 14):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/sci.space\n",
      "Currently loading the following topic (iteration 15):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/soc.religion.christian\n",
      "Currently loading the following topic (iteration 16):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/talk.politics.guns\n",
      "Currently loading the following topic (iteration 17):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/talk.politics.mideast\n",
      "Currently loading the following topic (iteration 18):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/talk.politics.misc\n",
      "Currently loading the following topic (iteration 19):\n",
      " \t/home/ekhongl/Codes/DL - Topic Modelling/data/raw_20news/20news-18828/talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "dat = []\n",
    "dat_y = []\n",
    "dat_y_cat = []\n",
    "\n",
    "for i in range(0,len(dir_src_classes)):\n",
    "    \n",
    "    print('Currently loading the following topic (iteration ' + str(i) + '):\\n \\t' + dir_src_classes[i])\n",
    "    dir_src_classes_file = list( map(lambda x: os.path.join(dir_src_classes[i], x), os.listdir(dir_src_classes[i])) )\n",
    "    \n",
    "    for ii in range(0, len(dir_src_classes_file)):\n",
    "        \n",
    "        dat_y.append(i)\n",
    "        \n",
    "        with open(dir_src_classes_file[ii], encoding='ISO-8859-1') as file:\n",
    "            dat.append(file.read().replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mapping sub topics 0-19 to broader topics 0-5\n",
    "y_map = [3,0,0,0,0,0,5,1,1,1,1,2,2,2,2,3,4,4,4,3]\n",
    "dat_y2 = [y_map[idx] for idx in dat_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export data\n",
    "pd.DataFrame( { '_label_granular' : dat_y, \n",
    "                '_label_overview' : dat_y2,\n",
    "                'document' : [' '.join(re.sub('[^a-zA-Z]+', ' ', doc).strip().split()) for doc in dat]}). \\\n",
    "                to_csv('data/raw_20news/20news.csv',\n",
    "                    index=False, sep=',', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Data cleaning -------\n",
      "Current progress: 0/18828\n",
      "Current progress: 100/18828\n",
      "Current progress: 200/18828\n",
      "Current progress: 300/18828\n",
      "Current progress: 400/18828\n",
      "Current progress: 500/18828\n",
      "Current progress: 600/18828\n",
      "Current progress: 700/18828\n",
      "Current progress: 800/18828\n",
      "Current progress: 900/18828\n",
      "Current progress: 1000/18828\n",
      "Current progress: 1100/18828\n",
      "Current progress: 1200/18828\n",
      "Current progress: 1300/18828\n",
      "Current progress: 1400/18828\n",
      "Current progress: 1500/18828\n",
      "Current progress: 1600/18828\n",
      "Current progress: 1700/18828\n",
      "Current progress: 1800/18828\n",
      "Current progress: 1900/18828\n",
      "Current progress: 2000/18828\n",
      "Current progress: 2100/18828\n",
      "Current progress: 2200/18828\n",
      "Current progress: 2300/18828\n",
      "Current progress: 2400/18828\n",
      "Current progress: 2500/18828\n",
      "Current progress: 2600/18828\n",
      "Current progress: 2700/18828\n",
      "Current progress: 2800/18828\n",
      "Current progress: 2900/18828\n",
      "Current progress: 3000/18828\n",
      "Current progress: 3100/18828\n",
      "Current progress: 3200/18828\n",
      "Current progress: 3300/18828\n",
      "Current progress: 3400/18828\n",
      "Current progress: 3500/18828\n",
      "Current progress: 3600/18828\n",
      "Current progress: 3700/18828\n",
      "Current progress: 3800/18828\n",
      "Current progress: 3900/18828\n",
      "Current progress: 4000/18828\n",
      "Current progress: 4100/18828\n",
      "Current progress: 4200/18828\n",
      "Current progress: 4300/18828\n",
      "Current progress: 4400/18828\n",
      "Current progress: 4500/18828\n",
      "Current progress: 4600/18828\n",
      "Current progress: 4700/18828\n",
      "Current progress: 4800/18828\n",
      "Current progress: 4900/18828\n",
      "Current progress: 5000/18828\n",
      "Current progress: 5100/18828\n",
      "Current progress: 5200/18828\n",
      "Current progress: 5300/18828\n",
      "Current progress: 5400/18828\n",
      "Current progress: 5500/18828\n",
      "Current progress: 5600/18828\n",
      "Current progress: 5700/18828\n",
      "Current progress: 5800/18828\n",
      "Current progress: 5900/18828\n",
      "Current progress: 6000/18828\n",
      "Current progress: 6100/18828\n",
      "Current progress: 6200/18828\n",
      "Current progress: 6300/18828\n",
      "Current progress: 6400/18828\n",
      "Current progress: 6500/18828\n",
      "Current progress: 6600/18828\n",
      "Current progress: 6700/18828\n",
      "Current progress: 6800/18828\n",
      "Current progress: 6900/18828\n",
      "Current progress: 7000/18828\n",
      "Current progress: 7100/18828\n",
      "Current progress: 7200/18828\n",
      "Current progress: 7300/18828\n",
      "Current progress: 7400/18828\n",
      "Current progress: 7500/18828\n",
      "Current progress: 7600/18828\n",
      "Current progress: 7700/18828\n",
      "Current progress: 7800/18828\n",
      "Current progress: 7900/18828\n",
      "Current progress: 8000/18828\n",
      "Current progress: 8100/18828\n",
      "Current progress: 8200/18828\n",
      "Current progress: 8300/18828\n",
      "Current progress: 8400/18828\n",
      "Current progress: 8500/18828\n",
      "Current progress: 8600/18828\n",
      "Current progress: 8700/18828\n",
      "Current progress: 8800/18828\n",
      "Current progress: 8900/18828\n",
      "Current progress: 9000/18828\n",
      "Current progress: 9100/18828\n",
      "Current progress: 9200/18828\n",
      "Current progress: 9300/18828\n",
      "Current progress: 9400/18828\n",
      "Current progress: 9500/18828\n",
      "Current progress: 9600/18828\n",
      "Current progress: 9700/18828\n",
      "Current progress: 9800/18828\n",
      "Current progress: 9900/18828\n",
      "Current progress: 10000/18828\n",
      "Current progress: 10100/18828\n",
      "Current progress: 10200/18828\n",
      "Current progress: 10300/18828\n",
      "Current progress: 10400/18828\n",
      "Current progress: 10500/18828\n",
      "Current progress: 10600/18828\n",
      "Current progress: 10700/18828\n",
      "Current progress: 10800/18828\n",
      "Current progress: 10900/18828\n",
      "Current progress: 11000/18828\n",
      "Current progress: 11100/18828\n",
      "Current progress: 11200/18828\n",
      "Current progress: 11300/18828\n",
      "Current progress: 11400/18828\n",
      "Current progress: 11500/18828\n",
      "Current progress: 11600/18828\n",
      "Current progress: 11700/18828\n",
      "Current progress: 11800/18828\n",
      "Current progress: 11900/18828\n",
      "Current progress: 12000/18828\n",
      "Current progress: 12100/18828\n",
      "Current progress: 12200/18828\n",
      "Current progress: 12300/18828\n",
      "Current progress: 12400/18828\n",
      "Current progress: 12500/18828\n",
      "Current progress: 12600/18828\n",
      "Current progress: 12700/18828\n",
      "Current progress: 12800/18828\n",
      "Current progress: 12900/18828\n",
      "Current progress: 13000/18828\n",
      "Current progress: 13100/18828\n",
      "Current progress: 13200/18828\n",
      "Current progress: 13300/18828\n",
      "Current progress: 13400/18828\n",
      "Current progress: 13500/18828\n",
      "Current progress: 13600/18828\n",
      "Current progress: 13700/18828\n",
      "Current progress: 13800/18828\n",
      "Current progress: 13900/18828\n",
      "Current progress: 14000/18828\n",
      "Current progress: 14100/18828\n",
      "Current progress: 14200/18828\n",
      "Current progress: 14300/18828\n",
      "Current progress: 14400/18828\n",
      "Current progress: 14500/18828\n",
      "Current progress: 14600/18828\n",
      "Current progress: 14700/18828\n",
      "Current progress: 14800/18828\n",
      "Current progress: 14900/18828\n",
      "Current progress: 15000/18828\n",
      "Current progress: 15100/18828\n",
      "Current progress: 15200/18828\n",
      "Current progress: 15300/18828\n",
      "Current progress: 15400/18828\n",
      "Current progress: 15500/18828\n",
      "Current progress: 15600/18828\n",
      "Current progress: 15700/18828\n",
      "Current progress: 15800/18828\n",
      "Current progress: 15900/18828\n",
      "Current progress: 16000/18828\n",
      "Current progress: 16100/18828\n",
      "Current progress: 16200/18828\n",
      "Current progress: 16300/18828\n",
      "Current progress: 16400/18828\n",
      "Current progress: 16500/18828\n",
      "Current progress: 16600/18828\n",
      "Current progress: 16700/18828\n",
      "Current progress: 16800/18828\n",
      "Current progress: 16900/18828\n",
      "Current progress: 17000/18828\n",
      "Current progress: 17100/18828\n",
      "Current progress: 17200/18828\n",
      "Current progress: 17300/18828\n",
      "Current progress: 17400/18828\n",
      "Current progress: 17500/18828\n",
      "Current progress: 17600/18828\n",
      "Current progress: 17700/18828\n",
      "Current progress: 17800/18828\n",
      "Current progress: 17900/18828\n",
      "Current progress: 18000/18828\n",
      "Current progress: 18100/18828\n",
      "Current progress: 18200/18828\n",
      "Current progress: 18300/18828\n",
      "Current progress: 18400/18828\n",
      "Current progress: 18500/18828\n",
      "Current progress: 18600/18828\n",
      "Current progress: 18700/18828\n",
      "Current progress: 18800/18828\n"
     ]
    }
   ],
   "source": [
    "print('------- Data cleaning -------')                \n",
    "stopwords_en = stopwords.words('english')\n",
    "dat_clean = []\n",
    "for i in range(len(dat)):\n",
    "\n",
    "    ''' tokenization and punctuation removal '''\n",
    "    # uses nltk tokenization - e.g. shouldn't = [should, n't] instead of [shouldn, 't]\n",
    "    tmp_doc = nltk.tokenize.word_tokenize(dat[i].lower())\n",
    "    \n",
    "    # split words sperated by fullstops\n",
    "    tmp_doc_split = [w.split('.') for w in tmp_doc if len(w.split('.')) > 1]\n",
    "    # flatten list\n",
    "    tmp_doc_split = [i_sublist for i_list in tmp_doc_split for i_sublist in i_list]\n",
    "    # clean split words\n",
    "    tmp_doc_split = [w for w in tmp_doc_split if re.search('^[a-z]+$',w)]\n",
    "    \n",
    "    # drop punctuations\n",
    "    tmp_doc_clean = [w for w in tmp_doc if re.search('^[a-z]+$',w)]\n",
    "    tmp_doc_clean.extend(tmp_doc_split)\n",
    "\n",
    "    ''' stop word removal'''\n",
    "    tmp_doc_clean_stop = [w for w in tmp_doc_clean if w not in stopwords_en]\n",
    "    #retain only words with 2 characters or more\n",
    "    tmp_doc_clean_stop = [w for w in  tmp_doc_clean_stop if len(w) >2]\n",
    "    \n",
    "    ''' stemming (using the Porter's algorithm)'''\n",
    "    tmp_doc_clean_stop_stemmed = [ps.stem(w) for w in tmp_doc_clean_stop]\n",
    "    dat_clean.append(tmp_doc_clean_stop_stemmed)\n",
    "    \n",
    "    #print progress\n",
    "    if i % 100 == 0: print( 'Current progress: ' + str(i) + '/' + str(len(dat)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekhongl/.conda/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv('data/clean_20news.csv', sep=\",\")\n",
    "\n",
    "\n",
    "docs = [ast.literal_eval(doc) for doc in dat['document'].tolist()]\n",
    "\n",
    "all_words = [word for doc in docs for word in doc]\n",
    "pd_all_words = pd.DataFrame({'words' : all_words})\n",
    "pd_unq_word_counts = pd.DataFrame({'count' : pd_all_words.groupby('words').size()}).reset_index().sort('count', ascending = False)\n",
    "\n",
    "# follow's research paper's top 2000 vocabulary (previously only took data with counts of words more than 150)\n",
    "pd_unq_word_counts_filtered = pd_unq_word_counts.head(2000)\n",
    "list_unq_word_filtered = list( pd_unq_word_counts_filtered.ix[:,0] )\n",
    "len(list_unq_word_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage completion: 0.02631578947368421\n",
      "Percentage completion: 0.05263157894736842\n",
      "Percentage completion: 0.07894736842105263\n",
      "Percentage completion: 0.10526315789473684\n",
      "Percentage completion: 0.13157894736842105\n",
      "Percentage completion: 0.15789473684210525\n",
      "Percentage completion: 0.18421052631578946\n",
      "Percentage completion: 0.21052631578947367\n",
      "Percentage completion: 0.23684210526315788\n",
      "Percentage completion: 0.2631578947368421\n",
      "Percentage completion: 0.2894736842105263\n",
      "Percentage completion: 0.3157894736842105\n",
      "Percentage completion: 0.34210526315789475\n",
      "Percentage completion: 0.3684210526315789\n",
      "Percentage completion: 0.39473684210526316\n",
      "Percentage completion: 0.42105263157894735\n",
      "Percentage completion: 0.4473684210526316\n",
      "Percentage completion: 0.47368421052631576\n",
      "Percentage completion: 0.5\n",
      "Percentage completion: 0.5263157894736842\n",
      "Percentage completion: 0.5526315789473685\n",
      "Percentage completion: 0.5789473684210527\n",
      "Percentage completion: 0.6052631578947368\n",
      "Percentage completion: 0.631578947368421\n",
      "Percentage completion: 0.6578947368421053\n",
      "Percentage completion: 0.6842105263157895\n",
      "Percentage completion: 0.7105263157894737\n",
      "Percentage completion: 0.7368421052631579\n",
      "Percentage completion: 0.7631578947368421\n",
      "Percentage completion: 0.7894736842105263\n",
      "Percentage completion: 0.8157894736842105\n",
      "Percentage completion: 0.8421052631578947\n",
      "Percentage completion: 0.868421052631579\n",
      "Percentage completion: 0.8947368421052632\n",
      "Percentage completion: 0.9210526315789473\n",
      "Percentage completion: 0.9473684210526315\n",
      "Percentage completion: 0.9736842105263158\n",
      "Percentage completion: 1.0\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(input = 'content', lowercase = False, vocabulary = list_unq_word_filtered)\n",
    "\n",
    "iters = list(range(0,len(docs),500))\n",
    "iters.append(len(docs))\n",
    "dtm = np.array([] ).reshape(0,len(list_unq_word_filtered))\n",
    "for i in range(len(iters)-1):\n",
    "    dtm = np.concatenate( (dtm, list(map(lambda x: vec.fit_transform(x).toarray().sum(axis=0), docs[iters[i]:iters[i+1]] )) ), axis = 0)\n",
    "    print( 'Percentage completion: ' + str( (i+1) / (len(iters)-1) ) )\n",
    "\n",
    "colnames = list_unq_word_filtered\n",
    "colnames.insert(0,'_label_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data = np.c_[dat['label'].values, dtm], \n",
    "             columns = colnames). \\\n",
    "             to_csv( 'data/dtm_2000_20news.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data = np.c_[dat_y2, dtm], \n",
    "             columns = colnames). \\\n",
    "             to_csv( 'data/dtm_2000_20news_6class.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edu',\n",
       " 'subject',\n",
       " 'com',\n",
       " 'would',\n",
       " 'one',\n",
       " 'use',\n",
       " 'write',\n",
       " 'articl',\n",
       " 'like',\n",
       " 'get',\n",
       " 'peopl',\n",
       " 'know',\n",
       " 'think',\n",
       " 'time',\n",
       " 'say',\n",
       " 'also',\n",
       " 'make',\n",
       " 'work',\n",
       " 'could',\n",
       " 'want',\n",
       " 'good',\n",
       " 'new',\n",
       " 'system',\n",
       " 'year',\n",
       " 'right',\n",
       " 'see',\n",
       " 'need',\n",
       " 'way',\n",
       " 'even',\n",
       " 'may',\n",
       " 'well',\n",
       " 'look',\n",
       " 'thing',\n",
       " 'problem',\n",
       " 'god',\n",
       " 'file',\n",
       " 'tri',\n",
       " 'much',\n",
       " 'mani',\n",
       " 'first',\n",
       " 'max',\n",
       " 'two',\n",
       " 'question',\n",
       " 'window',\n",
       " 'take',\n",
       " 'call',\n",
       " 'believ',\n",
       " 'post',\n",
       " 'come',\n",
       " 'anyon',\n",
       " 'point',\n",
       " 'program',\n",
       " 'run',\n",
       " 'said',\n",
       " 'seem',\n",
       " 'mean',\n",
       " 'help',\n",
       " 'state',\n",
       " 'read',\n",
       " 'pleas',\n",
       " 'differ',\n",
       " 'drive',\n",
       " 'number',\n",
       " 'thank',\n",
       " 'someth',\n",
       " 'find',\n",
       " 'back',\n",
       " 'realli',\n",
       " 'game',\n",
       " 'sinc',\n",
       " 'includ',\n",
       " 'day',\n",
       " 'still',\n",
       " 'inform',\n",
       " 'give',\n",
       " 'reason',\n",
       " 'person',\n",
       " 'univers',\n",
       " 'christian',\n",
       " 'gener',\n",
       " 'go',\n",
       " 'govern',\n",
       " 'start',\n",
       " 'part',\n",
       " 'last',\n",
       " 'support',\n",
       " 'might',\n",
       " 'sure',\n",
       " 'ask',\n",
       " 'let',\n",
       " 'case',\n",
       " 'follow',\n",
       " 'law',\n",
       " 'never',\n",
       " 'set',\n",
       " 'comput',\n",
       " 'better',\n",
       " 'imag',\n",
       " 'interest',\n",
       " 'must',\n",
       " 'car',\n",
       " 'power',\n",
       " 'key',\n",
       " 'group',\n",
       " 'fact',\n",
       " 'anoth',\n",
       " 'without',\n",
       " 'world',\n",
       " 'possibl',\n",
       " 'etc',\n",
       " 'david',\n",
       " 'name',\n",
       " 'someon',\n",
       " 'got',\n",
       " 'tell',\n",
       " 'chang',\n",
       " 'avail',\n",
       " 'made',\n",
       " 'control',\n",
       " 'put',\n",
       " 'line',\n",
       " 'list',\n",
       " 'lot',\n",
       " 'live',\n",
       " 'data',\n",
       " 'word',\n",
       " 'space',\n",
       " 'actual',\n",
       " 'place',\n",
       " 'book',\n",
       " 'probabl',\n",
       " 'exist',\n",
       " 'card',\n",
       " 'around',\n",
       " 'happen',\n",
       " 'long',\n",
       " 'littl',\n",
       " 'softwar',\n",
       " 'howev',\n",
       " 'anyth',\n",
       " 'show',\n",
       " 'talk',\n",
       " 'play',\n",
       " 'gun',\n",
       " 'team',\n",
       " 'bit',\n",
       " 'keep',\n",
       " 'opinion',\n",
       " 'everi',\n",
       " 'best',\n",
       " 'kill',\n",
       " 'claim',\n",
       " 'john',\n",
       " 'consid',\n",
       " 'true',\n",
       " 'least',\n",
       " 'cours',\n",
       " 'idea',\n",
       " 'enough',\n",
       " 'base',\n",
       " 'chip',\n",
       " 'second',\n",
       " 'news',\n",
       " 'order',\n",
       " 'end',\n",
       " 'version',\n",
       " 'sourc',\n",
       " 'great',\n",
       " 'org',\n",
       " 'armenian',\n",
       " 'mail',\n",
       " 'nation',\n",
       " 'provid',\n",
       " 'answer',\n",
       " 'issu',\n",
       " 'note',\n",
       " 'public',\n",
       " 'though',\n",
       " 'either',\n",
       " 'far',\n",
       " 'human',\n",
       " 'send',\n",
       " 'thought',\n",
       " 'exampl',\n",
       " 'jesu',\n",
       " 'caus',\n",
       " 'requir',\n",
       " 'mark',\n",
       " 'life',\n",
       " 'current',\n",
       " 'els',\n",
       " 'found',\n",
       " 'refer',\n",
       " 'noth',\n",
       " 'hard',\n",
       " 'wrong',\n",
       " 'rather',\n",
       " 'real',\n",
       " 'old',\n",
       " 'respons',\n",
       " 'report',\n",
       " 'origin',\n",
       " 'effect',\n",
       " 'discuss',\n",
       " 'man',\n",
       " 'engin',\n",
       " 'machin',\n",
       " 'allow',\n",
       " 'quit',\n",
       " 'price',\n",
       " 'american',\n",
       " 'sever',\n",
       " 'gov',\n",
       " 'net',\n",
       " 'phone',\n",
       " 'disk',\n",
       " 'ye',\n",
       " 'bill',\n",
       " 'standard',\n",
       " 'done',\n",
       " 'next',\n",
       " 'email',\n",
       " 'free',\n",
       " 'kind',\n",
       " 'hope',\n",
       " 'seen',\n",
       " 'care',\n",
       " 'other',\n",
       " 'feel',\n",
       " 'suggest',\n",
       " 'mayb',\n",
       " 'address',\n",
       " 'research',\n",
       " 'yet',\n",
       " 'abl',\n",
       " 'turn',\n",
       " 'understand',\n",
       " 'object',\n",
       " 'win',\n",
       " 'applic',\n",
       " 'alway',\n",
       " 'buy',\n",
       " 'driver',\n",
       " 'access',\n",
       " 'type',\n",
       " 'sun',\n",
       " 'sound',\n",
       " 'ever',\n",
       " 'high',\n",
       " 'heard',\n",
       " 'mac',\n",
       " 'player',\n",
       " 'bad',\n",
       " 'develop',\n",
       " 'nasa',\n",
       " 'wrote',\n",
       " 'hand',\n",
       " 'result',\n",
       " 'user',\n",
       " 'messag',\n",
       " 'author',\n",
       " 'less',\n",
       " 'accept',\n",
       " 'evid',\n",
       " 'code',\n",
       " 'graphic',\n",
       " 'view',\n",
       " 'internet',\n",
       " 'manag',\n",
       " 'israel',\n",
       " 'home',\n",
       " 'whether',\n",
       " 'color',\n",
       " 'three',\n",
       " 'given',\n",
       " 'love',\n",
       " 'children',\n",
       " 'design',\n",
       " 'rememb',\n",
       " 'open',\n",
       " 'copi',\n",
       " 'servic',\n",
       " 'today',\n",
       " 'test',\n",
       " 'left',\n",
       " 'michael',\n",
       " 'jew',\n",
       " 'away',\n",
       " 'encrypt',\n",
       " 'moral',\n",
       " 'big',\n",
       " 'info',\n",
       " 'move',\n",
       " 'area',\n",
       " 'agre',\n",
       " 'cost',\n",
       " 'fire',\n",
       " 'appear',\n",
       " 'import',\n",
       " 'display',\n",
       " 'unit',\n",
       " 'posit',\n",
       " 'build',\n",
       " 'forc',\n",
       " 'check',\n",
       " 'presid',\n",
       " 'studi',\n",
       " 'sale',\n",
       " 'netcom',\n",
       " 'format',\n",
       " 'secur',\n",
       " 'creat',\n",
       " 'larg',\n",
       " 'commun',\n",
       " 'appl',\n",
       " 'religion',\n",
       " 'war',\n",
       " 'local',\n",
       " 'week',\n",
       " 'paul',\n",
       " 'ftp',\n",
       " 'oper',\n",
       " 'do',\n",
       " 'countri',\n",
       " 'major',\n",
       " 'matter',\n",
       " 'speed',\n",
       " 'compani',\n",
       " 'box',\n",
       " 'side',\n",
       " 'guy',\n",
       " 'wonder',\n",
       " 'complet',\n",
       " 'offer',\n",
       " 'mind',\n",
       " 'technolog',\n",
       " 'scienc',\n",
       " 'assum',\n",
       " 'stuff',\n",
       " 'protect',\n",
       " 'alreadi',\n",
       " 'uucp',\n",
       " 'church',\n",
       " 'becom',\n",
       " 'argument',\n",
       " 'center',\n",
       " 'perhap',\n",
       " 'experi',\n",
       " 'uiuc',\n",
       " 'close',\n",
       " 'rule',\n",
       " 'ibm',\n",
       " 'stop',\n",
       " 'steve',\n",
       " 'product',\n",
       " 'fax',\n",
       " 'save',\n",
       " 'specif',\n",
       " 'small',\n",
       " 'death',\n",
       " 'money',\n",
       " 'bibl',\n",
       " 'valu',\n",
       " 'came',\n",
       " 'memori',\n",
       " 'expect',\n",
       " 'mention',\n",
       " 'die',\n",
       " 'process',\n",
       " 'ago',\n",
       " 'offic',\n",
       " 'organ',\n",
       " 'hous',\n",
       " 'recent',\n",
       " 'mike',\n",
       " 'told',\n",
       " 'sell',\n",
       " 'month',\n",
       " 'packag',\n",
       " 'final',\n",
       " 'correct',\n",
       " 'monitor',\n",
       " 'pretti',\n",
       " 'form',\n",
       " 'rate',\n",
       " 'act',\n",
       " 'homosexu',\n",
       " 'perform',\n",
       " 'model',\n",
       " 'robert',\n",
       " 'andrew',\n",
       " 'hit',\n",
       " 'present',\n",
       " 'natur',\n",
       " 'receiv',\n",
       " 'whole',\n",
       " 'attack',\n",
       " 'statement',\n",
       " 'guess',\n",
       " 'instal',\n",
       " 'light',\n",
       " 'advanc',\n",
       " 'action',\n",
       " 'polit',\n",
       " 'bodi',\n",
       " 'often',\n",
       " 'deal',\n",
       " 'muslim',\n",
       " 'except',\n",
       " 'pass',\n",
       " 'went',\n",
       " 'friend',\n",
       " 'head',\n",
       " 'member',\n",
       " 'usual',\n",
       " 'board',\n",
       " 'comment',\n",
       " 'server',\n",
       " 'intern',\n",
       " 'sort',\n",
       " 'limit',\n",
       " 'april',\n",
       " 'simpli',\n",
       " 'continu',\n",
       " 'involv',\n",
       " 'histori',\n",
       " 'appreci',\n",
       " 'hear',\n",
       " 'command',\n",
       " 'everyth',\n",
       " 'plan',\n",
       " 'clipper',\n",
       " 'error',\n",
       " 'full',\n",
       " 'pay',\n",
       " 'carri',\n",
       " 'return',\n",
       " 'network',\n",
       " 'everyon',\n",
       " 'jim',\n",
       " 'level',\n",
       " 'regard',\n",
       " 'drug',\n",
       " 'anyway',\n",
       " 'speak',\n",
       " 'job',\n",
       " 'lead',\n",
       " 'contact',\n",
       " 'almost',\n",
       " 'bike',\n",
       " 'isra',\n",
       " 'term',\n",
       " 'convert',\n",
       " 'total',\n",
       " 'later',\n",
       " 'certainli',\n",
       " 'instead',\n",
       " 'sens',\n",
       " 'men',\n",
       " 'hold',\n",
       " 'faith',\n",
       " 'situat',\n",
       " 'devic',\n",
       " 'fan',\n",
       " 'suppos',\n",
       " 'christ',\n",
       " 'press',\n",
       " 'arm',\n",
       " 'mit',\n",
       " 'white',\n",
       " 'earth',\n",
       " 'activ',\n",
       " 'video',\n",
       " 'connect',\n",
       " 'although',\n",
       " 'basic',\n",
       " 'contain',\n",
       " 'text',\n",
       " 'cover',\n",
       " 'leav',\n",
       " 'washington',\n",
       " 'coupl',\n",
       " 'defin',\n",
       " 'function',\n",
       " 'citi',\n",
       " 'nice',\n",
       " 'sin',\n",
       " 'quot',\n",
       " 'explain',\n",
       " 'scsi',\n",
       " 'singl',\n",
       " 'period',\n",
       " 'truth',\n",
       " 'turkish',\n",
       " 'unless',\n",
       " 'anybodi',\n",
       " 'belief',\n",
       " 'site',\n",
       " 'decid',\n",
       " 'similar',\n",
       " 'clear',\n",
       " 'jewish',\n",
       " 'black',\n",
       " 'hell',\n",
       " 'size',\n",
       " 'definit',\n",
       " 'learn',\n",
       " 'school',\n",
       " 'night',\n",
       " 'appli',\n",
       " 'arab',\n",
       " 'document',\n",
       " 'page',\n",
       " 'repli',\n",
       " 'polic',\n",
       " 'within',\n",
       " 'individu',\n",
       " 'watch',\n",
       " 'atheist',\n",
       " 'relat',\n",
       " 'compar',\n",
       " 'privat',\n",
       " 'ground',\n",
       " 'stand',\n",
       " 'concern',\n",
       " 'thu',\n",
       " 'record',\n",
       " 'attempt',\n",
       " 'newsgroup',\n",
       " 'detail',\n",
       " 'hockey',\n",
       " 'releas',\n",
       " 'direct',\n",
       " 'road',\n",
       " 'addit',\n",
       " 'face',\n",
       " 'mode',\n",
       " 'figur',\n",
       " 'practic',\n",
       " 'weapon',\n",
       " 'legal',\n",
       " 'jame',\n",
       " 'fbi',\n",
       " 'accord',\n",
       " 'certain',\n",
       " 'mine',\n",
       " 'known',\n",
       " 'event',\n",
       " 'busi',\n",
       " 'past',\n",
       " 'stori',\n",
       " 'especi',\n",
       " 'clinton',\n",
       " 'top',\n",
       " 'took',\n",
       " 'screen',\n",
       " 'dave',\n",
       " 'wait',\n",
       " 'physic',\n",
       " 'hardwar',\n",
       " 'delet',\n",
       " 'purpos',\n",
       " 'field',\n",
       " 'dead',\n",
       " 'normal',\n",
       " 'brian',\n",
       " 'land',\n",
       " 'fine',\n",
       " 'saw',\n",
       " 'via',\n",
       " 'option',\n",
       " 'among',\n",
       " 'sorri',\n",
       " 'common',\n",
       " 'season',\n",
       " 'exactli',\n",
       " 'depart',\n",
       " 'faq',\n",
       " 'women',\n",
       " 'entir',\n",
       " 'notic',\n",
       " 'ignor',\n",
       " 'date',\n",
       " 'increas',\n",
       " 'goe',\n",
       " 'per',\n",
       " 'fast',\n",
       " 'peac',\n",
       " 'begin',\n",
       " 'rest',\n",
       " 'project',\n",
       " 'shot',\n",
       " 'low',\n",
       " 'particular',\n",
       " 'add',\n",
       " 'toronto',\n",
       " 'special',\n",
       " 'replac',\n",
       " 'describ',\n",
       " 'red',\n",
       " 'condit',\n",
       " 'simpl',\n",
       " 'port',\n",
       " 'request',\n",
       " 'print',\n",
       " 'taken',\n",
       " 'crime',\n",
       " 'output',\n",
       " 'polici',\n",
       " 'att',\n",
       " 'apr',\n",
       " 'sometim',\n",
       " 'million',\n",
       " 'islam',\n",
       " 'propos',\n",
       " 'tape',\n",
       " 'societi',\n",
       " 'cmu',\n",
       " 'medic',\n",
       " 'health',\n",
       " 'religi',\n",
       " 'blue',\n",
       " 'orbit',\n",
       " 'electron',\n",
       " 'due',\n",
       " 'defens',\n",
       " 'usa',\n",
       " 'paper',\n",
       " 'handl',\n",
       " 'observ',\n",
       " 'goal',\n",
       " 'pick',\n",
       " 'fail',\n",
       " 'bob',\n",
       " 'radio',\n",
       " 'easi',\n",
       " 'cut',\n",
       " 'burn',\n",
       " 'therefor',\n",
       " 'dod',\n",
       " 'front',\n",
       " 'peter',\n",
       " 'depend',\n",
       " 'seri',\n",
       " 'whatev',\n",
       " 'canada',\n",
       " 'algorithm',\n",
       " 'scott',\n",
       " 'murder',\n",
       " 'inc',\n",
       " 'lost',\n",
       " 'produc',\n",
       " 'associ',\n",
       " 'unix',\n",
       " 'section',\n",
       " 'manual',\n",
       " 'third',\n",
       " 'publish',\n",
       " 'font',\n",
       " 'prevent',\n",
       " 'market',\n",
       " 'flame',\n",
       " 'upon',\n",
       " 'cso',\n",
       " 'prefer',\n",
       " 'offici',\n",
       " 'absolut',\n",
       " 'futur',\n",
       " 'remov',\n",
       " 'score',\n",
       " 'frank',\n",
       " 'written',\n",
       " 'basebal',\n",
       " 'mous',\n",
       " 'air',\n",
       " 'main',\n",
       " 'ride',\n",
       " 'doubt',\n",
       " 'chanc',\n",
       " 'launch',\n",
       " 'method',\n",
       " 'ship',\n",
       " 'switch',\n",
       " 'miss',\n",
       " 'bu',\n",
       " 'longer',\n",
       " 'short',\n",
       " 'four',\n",
       " 'lie',\n",
       " 'theori',\n",
       " 'hour',\n",
       " 'jpeg',\n",
       " 'indic',\n",
       " 'tool',\n",
       " 'tax',\n",
       " 'water',\n",
       " 'prove',\n",
       " 'account',\n",
       " 'distribut',\n",
       " 'king',\n",
       " 'modem',\n",
       " 'insur',\n",
       " 'york',\n",
       " 'institut',\n",
       " 'select',\n",
       " 'earli',\n",
       " 'variou',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'leagu',\n",
       " 'koresh',\n",
       " 'administr',\n",
       " 'resourc',\n",
       " 'librari',\n",
       " 'qualiti',\n",
       " 'wish',\n",
       " 'greek',\n",
       " 'pictur',\n",
       " 'serv',\n",
       " 'lord',\n",
       " 'san',\n",
       " 'occur',\n",
       " 'directori',\n",
       " 'announc',\n",
       " 'digit',\n",
       " 'widget',\n",
       " 'thoma',\n",
       " 'court',\n",
       " 'tom',\n",
       " 'behind',\n",
       " 'letter',\n",
       " 'featur',\n",
       " 'young',\n",
       " 'solut',\n",
       " 'minor',\n",
       " 'rutger',\n",
       " 'charg',\n",
       " 'parti',\n",
       " 'shall',\n",
       " 'strong',\n",
       " 'gif',\n",
       " 'amount',\n",
       " 'choic',\n",
       " 'togeth',\n",
       " 'sign',\n",
       " 'smith',\n",
       " 'keith',\n",
       " 'logic',\n",
       " 'comp',\n",
       " 'draw',\n",
       " 'knowledg',\n",
       " 'fall',\n",
       " 'ram',\n",
       " 'agenc',\n",
       " 'ad',\n",
       " 'trade',\n",
       " 'anonym',\n",
       " 'share',\n",
       " 'virginia',\n",
       " 'popul',\n",
       " 'meet',\n",
       " 'plu',\n",
       " 'interpret',\n",
       " 'voic',\n",
       " 'entri',\n",
       " 'famili',\n",
       " 'food',\n",
       " 'load',\n",
       " 'bitnet',\n",
       " 'respect',\n",
       " 'decis',\n",
       " 'express',\n",
       " 'will',\n",
       " 'constitut',\n",
       " 'father',\n",
       " 'along',\n",
       " 'colorado',\n",
       " 'pat',\n",
       " 'commit',\n",
       " 'previou',\n",
       " 'minut',\n",
       " 'worth',\n",
       " 'russian',\n",
       " 'outsid',\n",
       " 'remain',\n",
       " 'fix',\n",
       " 'citizen',\n",
       " 'militari',\n",
       " 'near',\n",
       " 'measur',\n",
       " 'averag',\n",
       " 'soon',\n",
       " 'appar',\n",
       " 'chri',\n",
       " 'wire',\n",
       " 'student',\n",
       " 'feder',\n",
       " 'ga',\n",
       " 'necessari',\n",
       " 'eye',\n",
       " 'printer',\n",
       " 'doctor',\n",
       " 'usenet',\n",
       " 'fit',\n",
       " 'vote',\n",
       " 'technic',\n",
       " 'suppli',\n",
       " 'divis',\n",
       " 'judg',\n",
       " 'educ',\n",
       " 'richard',\n",
       " 'sent',\n",
       " 'languag',\n",
       " 'higher',\n",
       " 'secret',\n",
       " 'stanford',\n",
       " 'class',\n",
       " 'anim',\n",
       " 'respond',\n",
       " 'adam',\n",
       " 'interfac',\n",
       " 'crimin',\n",
       " 'mission',\n",
       " 'son',\n",
       " 'child',\n",
       " 'initi',\n",
       " 'cabl',\n",
       " 'eric',\n",
       " 'mile',\n",
       " 'recommend',\n",
       " 'clearli',\n",
       " 'station',\n",
       " 'toward',\n",
       " 'avoid',\n",
       " 'age',\n",
       " 'none',\n",
       " 'archiv',\n",
       " 'search',\n",
       " 'ide',\n",
       " 'owner',\n",
       " 'diseas',\n",
       " 'determin',\n",
       " 'disclaim',\n",
       " 'approach',\n",
       " 'fight',\n",
       " 'media',\n",
       " 'freedom',\n",
       " 'door',\n",
       " 'stay',\n",
       " 'georg',\n",
       " 'east',\n",
       " 'heart',\n",
       " 'seriou',\n",
       " 'purchas',\n",
       " 'implement',\n",
       " 'capabl',\n",
       " 'convers',\n",
       " 'stupid',\n",
       " 'bank',\n",
       " 'enforc',\n",
       " 'block',\n",
       " 'repres',\n",
       " 'realiz',\n",
       " 'otherwis',\n",
       " 'drop',\n",
       " 'success',\n",
       " 'unfortun',\n",
       " 'uunet',\n",
       " 'imagin',\n",
       " 'turk',\n",
       " 'commerci',\n",
       " 'cup',\n",
       " 'joe',\n",
       " 'fund',\n",
       " 'materi',\n",
       " 'danger',\n",
       " 'patient',\n",
       " 'separ',\n",
       " 'pitt',\n",
       " 'armenia',\n",
       " 'rang',\n",
       " 'serial',\n",
       " 'effort',\n",
       " 'hate',\n",
       " 'teach',\n",
       " 'late',\n",
       " 'street',\n",
       " 'gave',\n",
       " 'henri',\n",
       " 'improv',\n",
       " 'independ',\n",
       " 'reach',\n",
       " 'manufactur',\n",
       " 'insid',\n",
       " 'inde',\n",
       " 'berkeley',\n",
       " 'ac',\n",
       " 'store',\n",
       " 'folk',\n",
       " 'spend',\n",
       " 'roger',\n",
       " 'sex',\n",
       " 'choos',\n",
       " 'lack',\n",
       " 'confer',\n",
       " 'thousand',\n",
       " 'kid',\n",
       " 'grant',\n",
       " 'mass',\n",
       " 'equip',\n",
       " 'happi',\n",
       " 'bought',\n",
       " 'locat',\n",
       " 'directli',\n",
       " 'pitch',\n",
       " 'transfer',\n",
       " 'mil',\n",
       " 'matthew',\n",
       " 'surpris',\n",
       " 'built',\n",
       " 'microsoft',\n",
       " 'faster',\n",
       " 'altern',\n",
       " 'bear',\n",
       " 'dan',\n",
       " 'argu',\n",
       " 'concept',\n",
       " 'floppi',\n",
       " 'waco',\n",
       " 'upgrad',\n",
       " 'basi',\n",
       " 'dealer',\n",
       " 'cheap',\n",
       " 'sgi',\n",
       " 'jon',\n",
       " 'consist',\n",
       " 'william',\n",
       " 'troubl',\n",
       " 'intend',\n",
       " 'input',\n",
       " 'cpu',\n",
       " 'firearm',\n",
       " 'green',\n",
       " 'obvious',\n",
       " 'suffer',\n",
       " 'aid',\n",
       " 'tim',\n",
       " 'america',\n",
       " 'civil',\n",
       " 'util',\n",
       " 'warn',\n",
       " 'titl',\n",
       " 'half',\n",
       " 'turkey',\n",
       " 'obtain',\n",
       " 'angel',\n",
       " 'room',\n",
       " 'edit',\n",
       " 'translat',\n",
       " 'collect',\n",
       " 'ray',\n",
       " 'leader',\n",
       " 'genocid',\n",
       " 'rais',\n",
       " 'equal',\n",
       " 'step',\n",
       " 'armi',\n",
       " 'rel',\n",
       " 'compress',\n",
       " 'pain',\n",
       " 'predict',\n",
       " 'count',\n",
       " 'tradit',\n",
       " 'licens',\n",
       " 'whose',\n",
       " 'excel',\n",
       " 'batteri',\n",
       " 'extra',\n",
       " 'difficult',\n",
       " 'investig',\n",
       " 'environ',\n",
       " 'easili',\n",
       " 'motif',\n",
       " 'boston',\n",
       " 'agent',\n",
       " 'columbia',\n",
       " 'star',\n",
       " 'volum',\n",
       " 'train',\n",
       " 'risk',\n",
       " 'compil',\n",
       " 'establish',\n",
       " 'batf',\n",
       " 'nhl',\n",
       " 'signal',\n",
       " 'updat',\n",
       " 'punish',\n",
       " 'villag',\n",
       " 'enter',\n",
       " 'scriptur',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_unq_word_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the exported raw text and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>From mathew mathew mantis co uk Subject Alt At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>From mathew mathew mantis co uk Subject Alt At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>From I dbstu rz tu bs de Benedikt Rosenau Subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>From mathew mathew mantis co uk Subject Re uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>From strom Watson Ibm Com Rob Strom Subject Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>From I dbstu rz tu bs de Benedikt Rosenau Subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>From I dbstu rz tu bs de Benedikt Rosenau Subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re Don t more innocents die without th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re Ancient islamic rituals From bobbe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re Political Atheists From bobbe vice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re There must be a creator Maybe From ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re Americans and Evolution From halat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re Speculations From dgraham bmers bnr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>From rm ic ac uk Mr R Mellish Subject Re unive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>From kilman y fiu edu Yevgeny Gene Kilman Subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re islamic authority over women From l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject Re Ancient islamic rituals From livese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>From anthropo carina unm edu Dominick V Zurlo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>From keith cco caltech edu Keith Allan Schneid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18798</th>\n",
       "      <td>19</td>\n",
       "      <td>From sandvik newton apple com Kent Sandvik Sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18799</th>\n",
       "      <td>19</td>\n",
       "      <td>From sandvik newton apple com Kent Sandvik Sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18800</th>\n",
       "      <td>19</td>\n",
       "      <td>From daveb pogo wv tek com Dave Butler Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18801</th>\n",
       "      <td>19</td>\n",
       "      <td>From eeb quads uchicago edu E Elizabeth Bartle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18802</th>\n",
       "      <td>19</td>\n",
       "      <td>From mcelwre cnsvax uwec edu Subject LARSONIAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18803</th>\n",
       "      <td>19</td>\n",
       "      <td>From lwb cs utexas edu Lance W Bledsoe Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18804</th>\n",
       "      <td>19</td>\n",
       "      <td>From jmeritt mental MITRE ORG Jim Meritt Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18805</th>\n",
       "      <td>19</td>\n",
       "      <td>From lwb cs utexas edu Lance W Bledsoe Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18806</th>\n",
       "      <td>19</td>\n",
       "      <td>From livesey solntze wpd sgi com Jon Livesey S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18807</th>\n",
       "      <td>19</td>\n",
       "      <td>From cutter gloster via mind org cutter Subjec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18808</th>\n",
       "      <td>19</td>\n",
       "      <td>From arromdee jyusenkyou cs jhu edu Ken Arromd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18809</th>\n",
       "      <td>19</td>\n",
       "      <td>From pboxrud magnus acs ohio state edu Paul D ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18810</th>\n",
       "      <td>19</td>\n",
       "      <td>Subject Re rw Is Robert Weiss the only orthodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18811</th>\n",
       "      <td>19</td>\n",
       "      <td>From tbrent bank ecn purdue edu Timothy J Bren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18812</th>\n",
       "      <td>19</td>\n",
       "      <td>From prl csis dit csiro au Peter Lamb Subject ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18813</th>\n",
       "      <td>19</td>\n",
       "      <td>From Lynn Anderson dba lynn cs cmu edu Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18814</th>\n",
       "      <td>19</td>\n",
       "      <td>From kltensme infonode ingr com Kermit Tensmey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18815</th>\n",
       "      <td>19</td>\n",
       "      <td>From ktikkane phoenix oulu fi Kari Tikkanen Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18816</th>\n",
       "      <td>19</td>\n",
       "      <td>From kltensme infonode ingr com Kermit Tensmey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18817</th>\n",
       "      <td>19</td>\n",
       "      <td>From frank D S uucp Frank O Dwyer Subject Re T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18818</th>\n",
       "      <td>19</td>\n",
       "      <td>Subject Re Albert Sabin From rfox charlie usd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18819</th>\n",
       "      <td>19</td>\n",
       "      <td>From David R Sacco dsav andrew cmu edu Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18820</th>\n",
       "      <td>19</td>\n",
       "      <td>From neese cerritos edu Subject Hell In the Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18821</th>\n",
       "      <td>19</td>\n",
       "      <td>From sbuckley fraser sfu ca Stephen Buckley Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18822</th>\n",
       "      <td>19</td>\n",
       "      <td>From sbuckley fraser sfu ca Stephen Buckley Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18823</th>\n",
       "      <td>19</td>\n",
       "      <td>From sbuckley fraser sfu ca Stephen Buckley Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18824</th>\n",
       "      <td>19</td>\n",
       "      <td>From bakerj gtephx UUCP Jon Baker Subject Re A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18825</th>\n",
       "      <td>19</td>\n",
       "      <td>From pharvey quack kfu com Paul Harvey Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18826</th>\n",
       "      <td>19</td>\n",
       "      <td>From KEVXU CUNYVM BITNET Subject Re Info about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18827</th>\n",
       "      <td>19</td>\n",
       "      <td>From pharvey quack kfu com Paul Harvey Subject...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18828 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _label                                           document\n",
       "0           0  From mathew mathew mantis co uk Subject Alt At...\n",
       "1           0  From mathew mathew mantis co uk Subject Alt At...\n",
       "2           0  From I dbstu rz tu bs de Benedikt Rosenau Subj...\n",
       "3           0  From mathew mathew mantis co uk Subject Re uni...\n",
       "4           0  From strom Watson Ibm Com Rob Strom Subject Re...\n",
       "5           0  From I dbstu rz tu bs de Benedikt Rosenau Subj...\n",
       "6           0  From keith cco caltech edu Keith Allan Schneid...\n",
       "7           0  From I dbstu rz tu bs de Benedikt Rosenau Subj...\n",
       "8           0  From keith cco caltech edu Keith Allan Schneid...\n",
       "9           0  From keith cco caltech edu Keith Allan Schneid...\n",
       "10          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "11          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "12          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "13          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "14          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "15          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "16          0  Subject Re Don t more innocents die without th...\n",
       "17          0  Subject Re Ancient islamic rituals From bobbe ...\n",
       "18          0  Subject Re Political Atheists From bobbe vice ...\n",
       "19          0  Subject Re There must be a creator Maybe From ...\n",
       "20          0  Subject Re Americans and Evolution From halat ...\n",
       "21          0  Subject Re Speculations From dgraham bmers bnr...\n",
       "22          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "23          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "24          0  From rm ic ac uk Mr R Mellish Subject Re unive...\n",
       "25          0  From kilman y fiu edu Yevgeny Gene Kilman Subj...\n",
       "26          0  Subject Re islamic authority over women From l...\n",
       "27          0  Subject Re Ancient islamic rituals From livese...\n",
       "28          0  From anthropo carina unm edu Dominick V Zurlo ...\n",
       "29          0  From keith cco caltech edu Keith Allan Schneid...\n",
       "...       ...                                                ...\n",
       "18798      19  From sandvik newton apple com Kent Sandvik Sub...\n",
       "18799      19  From sandvik newton apple com Kent Sandvik Sub...\n",
       "18800      19  From daveb pogo wv tek com Dave Butler Subject...\n",
       "18801      19  From eeb quads uchicago edu E Elizabeth Bartle...\n",
       "18802      19  From mcelwre cnsvax uwec edu Subject LARSONIAN...\n",
       "18803      19  From lwb cs utexas edu Lance W Bledsoe Subject...\n",
       "18804      19  From jmeritt mental MITRE ORG Jim Meritt Syste...\n",
       "18805      19  From lwb cs utexas edu Lance W Bledsoe Subject...\n",
       "18806      19  From livesey solntze wpd sgi com Jon Livesey S...\n",
       "18807      19  From cutter gloster via mind org cutter Subjec...\n",
       "18808      19  From arromdee jyusenkyou cs jhu edu Ken Arromd...\n",
       "18809      19  From pboxrud magnus acs ohio state edu Paul D ...\n",
       "18810      19  Subject Re rw Is Robert Weiss the only orthodo...\n",
       "18811      19  From tbrent bank ecn purdue edu Timothy J Bren...\n",
       "18812      19  From prl csis dit csiro au Peter Lamb Subject ...\n",
       "18813      19  From Lynn Anderson dba lynn cs cmu edu Subject...\n",
       "18814      19  From kltensme infonode ingr com Kermit Tensmey...\n",
       "18815      19  From ktikkane phoenix oulu fi Kari Tikkanen Su...\n",
       "18816      19  From kltensme infonode ingr com Kermit Tensmey...\n",
       "18817      19  From frank D S uucp Frank O Dwyer Subject Re T...\n",
       "18818      19  Subject Re Albert Sabin From rfox charlie usd ...\n",
       "18819      19  From David R Sacco dsav andrew cmu edu Subject...\n",
       "18820      19  From neese cerritos edu Subject Hell In the Ki...\n",
       "18821      19  From sbuckley fraser sfu ca Stephen Buckley Su...\n",
       "18822      19  From sbuckley fraser sfu ca Stephen Buckley Su...\n",
       "18823      19  From sbuckley fraser sfu ca Stephen Buckley Su...\n",
       "18824      19  From bakerj gtephx UUCP Jon Baker Subject Re A...\n",
       "18825      19  From pharvey quack kfu com Paul Harvey Subject...\n",
       "18826      19  From KEVXU CUNYVM BITNET Subject Re Info about...\n",
       "18827      19  From pharvey quack kfu com Paul Harvey Subject...\n",
       "\n",
       "[18828 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw_20news/20news.csv', sep=\",\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
