{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREVIOUS\n",
    "## gibbs sampler where uncessary recalculation of doc len was done for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN 5105)\n",
      "/home/ekhongl/.conda/envs/py3/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "theano_rng = T.shared_randomstreams.RandomStreams(1234)\n",
    "W_values = np.array([[1,1],[1,1]], dtype=theano.config.floatX)\n",
    "bvis_values = np.array([1,1], dtype=theano.config.floatX)\n",
    "bhid_values = np.array([1,1], dtype=theano.config.floatX)\n",
    "W = theano.shared(W_values)\n",
    "vbias = theano.shared(bvis_values)\n",
    "hbias = theano.shared(bhid_values)\n",
    "\n",
    "def propup(vis, v0_doc_len):\n",
    "        pre_sigmoid_activation = T.dot(vis, W) + T.dot(hbias.reshape([1,hbias.shape[0]]).T,v0_doc_len).T        #---------------------------[edited]\n",
    "        return [pre_sigmoid_activation, T.nnet.sigmoid(pre_sigmoid_activation)]\n",
    "\n",
    "def sample_h_given_v(v0_sample, v0_doc_len):\n",
    "    v0_doc_len = v0_doc_len.reshape([1,ipt.shape[0]])\n",
    "    pre_sigmoid_h1, h1_mean = propup(v0_sample, v0_doc_len)\n",
    "    h1_sample = theano_rng.binomial(size=h1_mean.shape,\n",
    "                                         n=1, p=h1_mean,\n",
    "                                         dtype=theano.config.floatX)\n",
    "    return [pre_sigmoid_h1, h1_mean, h1_sample]\n",
    "\n",
    "def propdown(hid):\n",
    "    pre_softmax_activation = T.dot(hid, W.T) + vbias                               #---------------------------[edited]\n",
    "    return [pre_softmax_activation, T.nnet.softmax(pre_softmax_activation)]\n",
    "\n",
    "def sample_v_given_h(h0_sample, v0_doc_len):\n",
    "    v0_doc_len = v0_doc_len.reshape([1,ipt.shape[0]])\n",
    "    pre_softmax_v1, v1_mean = propdown(h0_sample)\n",
    "    v1_sample = theano_rng.multinomial(size=None,\n",
    "                                         n=v0_doc_len, pvals=v1_mean,\n",
    "                                         dtype=theano.config.floatX)               #---------------------------[edited]\n",
    "    v1_doc_len = v1_sample[0].sum(axis=1)\n",
    "    return [pre_softmax_v1, v1_mean, v1_sample, v1_doc_len]\n",
    "\n",
    "def gibbs_hvh(h0_sample, v0_doc_len):\n",
    "    pre_softmax_v1, v1_mean, v1_sample, v1_doc_len = sample_v_given_h(h0_sample, v0_doc_len)\n",
    "    pre_sigmoid_h1, h1_mean, h1_sample = sample_h_given_v(v1_sample, v0_doc_len)\n",
    "    return [pre_sigmoid_h1[0], h1_mean[0], h1_sample[0],\n",
    "            pre_softmax_v1, v1_mean, v1_sample[0], v1_doc_len]                        #---------------------------[edited]\n",
    "\n",
    "\n",
    "ipt = T.matrix()\n",
    "ipt_rSum = ipt.sum(axis=1)\n",
    "\n",
    "pre_sigmoid_ph, ph_mean, ph_sample = sample_h_given_v(ipt, ipt_rSum)\n",
    "chain_start = ph_sample\n",
    "\n",
    "results, updates = theano.scan( fn = gibbs_hvh,\n",
    "                                outputs_info = [None, None, chain_start, None, None, None, ipt_rSum],\n",
    "                                n_steps=5)\n",
    "\n",
    "hgv = theano.function( [ipt], outputs=results, updates = updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.array([[1,6,],[1,3],[5,1]], dtype = theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 14.  14.]\n",
      "  [  8.   8.]\n",
      "  [ 12.  12.]]\n",
      "\n",
      " [[ 14.  14.]\n",
      "  [  8.   8.]\n",
      "  [ 12.  12.]]\n",
      "\n",
      " [[ 14.  14.]\n",
      "  [  8.   8.]\n",
      "  [ 12.  12.]]\n",
      "\n",
      " [[ 14.  14.]\n",
      "  [  8.   8.]\n",
      "  [ 12.  12.]]\n",
      "\n",
      " [[ 14.  14.]\n",
      "  [  8.   8.]\n",
      "  [ 12.  12.]]]\n",
      "[[[ 0.99999917  0.99999917]\n",
      "  [ 0.99966466  0.99966466]\n",
      "  [ 0.9999938   0.9999938 ]]\n",
      "\n",
      " [[ 0.99999917  0.99999917]\n",
      "  [ 0.99966466  0.99966466]\n",
      "  [ 0.9999938   0.9999938 ]]\n",
      "\n",
      " [[ 0.99999917  0.99999917]\n",
      "  [ 0.99966466  0.99966466]\n",
      "  [ 0.9999938   0.9999938 ]]\n",
      "\n",
      " [[ 0.99999917  0.99999917]\n",
      "  [ 0.99966466  0.99966466]\n",
      "  [ 0.9999938   0.9999938 ]]\n",
      "\n",
      " [[ 0.99999917  0.99999917]\n",
      "  [ 0.99966466  0.99966466]\n",
      "  [ 0.9999938   0.9999938 ]]]\n",
      "[[[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]]\n",
      "[[[ 3.  3.]\n",
      "  [ 3.  3.]\n",
      "  [ 3.  3.]]\n",
      "\n",
      " [[ 3.  3.]\n",
      "  [ 3.  3.]\n",
      "  [ 3.  3.]]\n",
      "\n",
      " [[ 3.  3.]\n",
      "  [ 3.  3.]\n",
      "  [ 3.  3.]]\n",
      "\n",
      " [[ 3.  3.]\n",
      "  [ 3.  3.]\n",
      "  [ 3.  3.]]\n",
      "\n",
      " [[ 3.  3.]\n",
      "  [ 3.  3.]\n",
      "  [ 3.  3.]]]\n",
      "[[[ 0.5  0.5]\n",
      "  [ 0.5  0.5]\n",
      "  [ 0.5  0.5]]\n",
      "\n",
      " [[ 0.5  0.5]\n",
      "  [ 0.5  0.5]\n",
      "  [ 0.5  0.5]]\n",
      "\n",
      " [[ 0.5  0.5]\n",
      "  [ 0.5  0.5]\n",
      "  [ 0.5  0.5]]\n",
      "\n",
      " [[ 0.5  0.5]\n",
      "  [ 0.5  0.5]\n",
      "  [ 0.5  0.5]]\n",
      "\n",
      " [[ 0.5  0.5]\n",
      "  [ 0.5  0.5]\n",
      "  [ 0.5  0.5]]]\n",
      "[[[ 4.  3.]\n",
      "  [ 2.  2.]\n",
      "  [ 4.  2.]]\n",
      "\n",
      " [[ 3.  4.]\n",
      "  [ 3.  1.]\n",
      "  [ 2.  4.]]\n",
      "\n",
      " [[ 1.  6.]\n",
      "  [ 1.  3.]\n",
      "  [ 2.  4.]]\n",
      "\n",
      " [[ 4.  3.]\n",
      "  [ 0.  4.]\n",
      "  [ 1.  5.]]\n",
      "\n",
      " [[ 3.  4.]\n",
      "  [ 2.  2.]\n",
      "  [ 3.  3.]]]\n",
      "[[ 7.  4.  6.]\n",
      " [ 7.  4.  6.]\n",
      " [ 7.  4.  6.]\n",
      " [ 7.  4.  6.]\n",
      " [ 7.  4.  6.]]\n"
     ]
    }
   ],
   "source": [
    "output = hgv(b)\n",
    "[out_1,out_2,out_3,out_4,out_5,out_6,out_7] = output\n",
    "print(out_1)\n",
    "print(out_2)\n",
    "print(out_3)\n",
    "print(out_4)\n",
    "print(out_5)\n",
    "print(out_6)\n",
    "print(out_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CURRENT\n",
    "## gibbs sampler where unecessary recalculation of doc len was dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "theano_rng = T.shared_randomstreams.RandomStreams(1234)\n",
    "W_values = np.array([[.1,-.4],[5,.4]], dtype=theano.config.floatX)\n",
    "bvis_values = np.array([0.5,-0.6], dtype=theano.config.floatX)\n",
    "bhid_values = np.array([-2,1], dtype=theano.config.floatX)\n",
    "W = theano.shared(W_values)\n",
    "vbias = theano.shared(bvis_values)\n",
    "hbias = theano.shared(bhid_values)\n",
    "\n",
    "def propup(vis, v_doc_len):\n",
    "        pre_sigmoid_activation = T.dot(vis, W) + T.dot(hbias.reshape([1,hbias.shape[0]]).T,v_doc_len).T        #---------------------------[edited]\n",
    "        return [pre_sigmoid_activation, T.nnet.sigmoid(pre_sigmoid_activation)]\n",
    "\n",
    "def sample_h_given_v(v0_sample, v_doc_len):\n",
    "    pre_sigmoid_h1, h1_mean = propup(v0_sample, v_doc_len)\n",
    "    h1_sample = theano_rng.binomial(size=h1_mean.shape,\n",
    "                                         n=1, p=h1_mean,\n",
    "                                         dtype=theano.config.floatX)\n",
    "    return [pre_sigmoid_h1, h1_mean, h1_sample]\n",
    "\n",
    "def propdown(hid):\n",
    "    pre_softmax_activation = T.dot(hid, W.T) + vbias                               #---------------------------[edited]\n",
    "    return [pre_softmax_activation, T.nnet.softmax(pre_softmax_activation)]\n",
    "\n",
    "def sample_v_given_h(h0_sample, v_doc_len):\n",
    "    pre_softmax_v1, v1_mean = propdown(h0_sample)\n",
    "    v1_sample = theano_rng.multinomial(size=None,\n",
    "                                         n=v_doc_len, pvals=v1_mean,\n",
    "                                         dtype=theano.config.floatX)               #---------------------------[edited]\n",
    "    return [pre_softmax_v1, v1_mean, v1_sample]\n",
    "\n",
    "def gibbs_hvh(h0_sample, v_doc_len):\n",
    "    pre_softmax_v1, v1_mean, v1_sample = sample_v_given_h(h0_sample, v_doc_len)\n",
    "    pre_sigmoid_h1, h1_mean, h1_sample = sample_h_given_v(v1_sample, v_doc_len)\n",
    "    return [pre_softmax_v1,    v1_mean,    v1_sample[0],\n",
    "            pre_sigmoid_h1[0], h1_mean[0], h1_sample[0] ]                        #---------------------------[edited]\n",
    "\n",
    "\n",
    "ipt = T.matrix()\n",
    "ipt_rSum = ipt.sum(axis=1).reshape([1,ipt.shape[0]])\n",
    "\n",
    "pre_sigmoid_ph, ph_mean, ph_sample = sample_h_given_v(ipt, ipt_rSum)\n",
    "chain_start = ph_sample\n",
    "\n",
    "results, updates = theano.scan( fn = gibbs_hvh,\n",
    "                                outputs_info = [None, None, None, None, None, chain_start],\n",
    "                                non_sequences = ipt_rSum,\n",
    "                                n_steps=2)\n",
    "\n",
    "hgv = theano.function( [ipt], outputs=results, updates = updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.19999999  4.80000019]\n",
      "  [ 0.19999999  4.80000019]\n",
      "  [ 0.09999999 -0.20000002]]\n",
      "\n",
      " [[ 0.19999999  4.80000019]\n",
      "  [ 0.19999999  4.80000019]\n",
      "  [ 0.09999999 -0.20000002]]]\n",
      "[[[ 0.0099518   0.99004823]\n",
      "  [ 0.0099518   0.99004823]\n",
      "  [ 0.57444257  0.42555746]]\n",
      "\n",
      " [[ 0.0099518   0.99004823]\n",
      "  [ 0.0099518   0.99004823]\n",
      "  [ 0.57444257  0.42555746]]]\n",
      "[[[ 0.  7.]\n",
      "  [ 0.  4.]\n",
      "  [ 4.  2.]]\n",
      "\n",
      " [[ 0.  7.]\n",
      "  [ 0.  4.]\n",
      "  [ 5.  1.]]]\n",
      "[[[ 21.           9.80000019]\n",
      "  [ 12.           5.5999999 ]\n",
      "  [ -1.60000038   5.19999981]]\n",
      "\n",
      " [[ 21.           9.80000019]\n",
      "  [ 12.           5.5999999 ]\n",
      "  [ -6.5          4.4000001 ]]]\n",
      "[[[ 1.          0.99994457]\n",
      "  [ 0.9999938   0.99631572]\n",
      "  [ 0.16798155  0.99451369]]\n",
      "\n",
      " [[ 1.          0.99994457]\n",
      "  [ 0.9999938   0.99631572]\n",
      "  [ 0.00150118  0.98787153]]]\n",
      "[[[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 0.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 0.  1.]]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1,6,],[1,3],[5,1]], dtype = theano.config.floatX)\n",
    "output = hgv(b)\n",
    "[out_1,out_2,out_3,out_4,out_5,out_6] = output\n",
    "print(out_1)\n",
    "print(out_2)\n",
    "print(out_3)\n",
    "print(out_4)\n",
    "print(out_5)\n",
    "print(out_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## piecewise codes to follow the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.  14.]]\n",
      "[[ 0.99999917  0.99999917]]\n",
      "[[ 1.  1.]]\n",
      "[[ 3.  3.]]\n",
      "[[ 0.5  0.5]]\n",
      "[[ 3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "# iter 0: use v0 to initialize [pre_sigmoid_ph, ph_mean, ph_sample]_0\n",
    "bias = bvis_values.reshape([1,bvis_values.shape[0]])\n",
    "doc_len = b[0,:].sum()\n",
    "pre_sigmoid_ph0 = (T.dot(b[0,:],W_values) + T.dot(bias.T,doc_len).T).eval()\n",
    "ph0_mean = T.nnet.sigmoid(pre_sigmoid_ph0).eval()\n",
    "ph0_sample = theano_rng.binomial(size=ph0_mean.shape,n=1, p=ph0_mean, dtype=theano.config.floatX).eval()\n",
    "print(pre_sigmoid_ph0)\n",
    "print(ph0_mean)\n",
    "print(ph0_sample)\n",
    "\n",
    "# iter 1:\n",
    "pre_softmax_v1 = T.dot(ph0_sample, W_values.T) + bias\n",
    "v1_mean = T.nnet.softmax(pre_softmax_v1)\n",
    "v1_sample = theano_rng.multinomial(size=None,n=doc_len, pvals=v1_mean, dtype=theano.config.floatX)\n",
    "print(pre_softmax_v1.eval())\n",
    "print(v1_mean.eval())\n",
    "print(v1_sample.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'CudaNdarray([ 1.  1.])'\n",
      "[[ 7.  4.  6.]\n",
      " [ 7.  4.  6.]]\n",
      "[[ 7.  7.]\n",
      " [ 4.  4.]\n",
      " [ 6.  6.]]\n",
      "[[ 14.  14.]\n",
      " [  8.   8.]\n",
      " [ 12.  12.]]\n"
     ]
    }
   ],
   "source": [
    "doc_len = theano.shared(b.sum(axis=1))\n",
    "print(hbias.eval())\n",
    "print(T.outer(hbias,doc_len).eval())\n",
    "print(T.outer(doc_len,hbias).eval())\n",
    "pre_sigmoid_ph0 = (T.dot(b,W) + T.outer(doc_len,hbias))\n",
    "print(pre_sigmoid_ph0.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  0.]\n",
      " [ 4.  0.]\n",
      " [ 6.  0.]]\n"
     ]
    }
   ],
   "source": [
    "doc_len = theano.shared(b.sum(axis=1))\n",
    "v_star = T.zeros_like(theano.shared(b))\n",
    "v_star = T.set_subtensor(v_star[:,0], doc_len )\n",
    "print(v_star.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "theano_rng = T.shared_randomstreams.RandomStreams(1234)\n",
    "W_values = np.array([[1,1,1],[1,1,1]], dtype=theano.config.floatX).T #3 visibles and 2 hidden\n",
    "bvis_values = np.array([1,1,1], dtype=theano.config.floatX)\n",
    "bhid_values = np.array([0.5,0.5], dtype=theano.config.floatX)\n",
    "#W_values = np.array([[.1,-.4],[5,.4],[-.5,.3]], dtype=theano.config.floatX)\n",
    "#bvis_values = np.array([0.5,-0.6], dtype=theano.config.floatX)\n",
    "#bhid_values = np.array([-2,1,2], dtype=theano.config.floatX)\n",
    "W = theano.shared(W_values)\n",
    "vbias = theano.shared(bvis_values)\n",
    "hbias = theano.shared(bhid_values)\n",
    "\n",
    "def propup(vis, v_doc_len):\n",
    "        pre_sigmoid_activation = T.dot(vis, W) + T.outer(v_doc_len,hbias)        #---------------------------[edited]\n",
    "        return [pre_sigmoid_activation, T.nnet.sigmoid(pre_sigmoid_activation)]\n",
    "\n",
    "def sample_h_given_v(v0_sample, v_doc_len):\n",
    "    pre_sigmoid_h1, h1_mean = propup(v0_sample, v_doc_len)\n",
    "    h1_sample = theano_rng.binomial(size=h1_mean.shape,\n",
    "                                         n=1, p=h1_mean,\n",
    "                                         dtype=theano.config.floatX)\n",
    "    return [pre_sigmoid_h1, h1_mean, h1_sample]\n",
    "\n",
    "def propdown(hid):\n",
    "    pre_softmax_activation = T.dot(hid, W.T) + vbias                               #---------------------------[edited]\n",
    "    return [pre_softmax_activation, T.nnet.softmax(pre_softmax_activation)]\n",
    "\n",
    "def sample_v_given_h(h0_sample, v_doc_len):\n",
    "    pre_softmax_v1, v1_mean = propdown(h0_sample)\n",
    "    v1_sample = theano_rng.multinomial(size=None,\n",
    "                                         n=v_doc_len, pvals=v1_mean,\n",
    "                                         dtype=theano.config.floatX)               #---------------------------[edited]\n",
    "    return [pre_softmax_v1, v1_mean, v1_sample]\n",
    "\n",
    "def gibbs_hvh(h0_sample, v_doc_len):\n",
    "    pre_softmax_v1, v1_mean, v1_sample = sample_v_given_h(h0_sample, v_doc_len)\n",
    "    pre_sigmoid_h1, h1_mean, h1_sample = sample_h_given_v(v1_sample, v_doc_len)\n",
    "    return [pre_softmax_v1,    v1_mean,    v1_sample,\n",
    "            pre_sigmoid_h1, h1_mean, h1_sample ]                        #---------------------------[edited]\n",
    "\n",
    "\n",
    "ipt = T.matrix()\n",
    "ipt_rSum = ipt.sum(axis=1)\n",
    "\n",
    "pre_sigmoid_ph, ph_mean, ph_sample = sample_h_given_v(ipt, ipt_rSum)\n",
    "chain_start = ph_sample\n",
    "\n",
    "results, updates = theano.scan( fn = gibbs_hvh,\n",
    "                                outputs_info = [None, None, None, None, None, chain_start],\n",
    "                                non_sequences = ipt_rSum,\n",
    "                                n_steps=2 )\n",
    "\n",
    "hgv = theano.function( [ipt], outputs=results, updates = updates)\n",
    "\n",
    "b = theano.shared(np.array([[1,6,1],[1,3,2],[5,2,1],[5,1,2]], dtype = theano.config.floatX) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'CudaNdarray([ 0.5  0.5])'\n",
      "[ 8.  6.  8.  8.]\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[[ 8.  8.]\n",
      " [ 6.  6.]\n",
      " [ 8.  8.]\n",
      " [ 8.  8.]]\n",
      "[[ 4.  4.]\n",
      " [ 3.  3.]\n",
      " [ 4.  4.]\n",
      " [ 4.  4.]]\n",
      "[[ 12.  12.]\n",
      " [  9.   9.]\n",
      " [ 12.  12.]\n",
      " [ 12.  12.]]\n",
      "[[ 0.9999938   0.9999938 ]\n",
      " [ 0.99987662  0.99987662]\n",
      " [ 0.9999938   0.9999938 ]\n",
      " [ 0.9999938   0.9999938 ]]\n"
     ]
    }
   ],
   "source": [
    "b_sum = b.sum(axis=1) #.reshape([1,b.shape[0]])\n",
    "print(hbias.eval())\n",
    "print(b_sum.eval())\n",
    "print(W_values)\n",
    "print(T.dot(b,W).eval())\n",
    "print(T.outer(b_sum,hbias).eval())\n",
    "print((T.dot(b,W) + T.outer(b_sum,hbias)).eval())\n",
    "print( T.nnet.sigmoid(T.dot(b,W) + T.outer(b_sum,hbias)).eval() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.  12.]\n",
      " [  9.   9.]\n",
      " [ 12.  12.]\n",
      " [ 12.  12.]]\n",
      "[[ 0.9999938   0.9999938 ]\n",
      " [ 0.99987662  0.99987662]\n",
      " [ 0.9999938   0.9999938 ]\n",
      " [ 0.9999938   0.9999938 ]]\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "[out1,out2,out3] = sample_h_given_v(b,b_sum)\n",
    "print(out1.eval())\n",
    "print(out2.eval())\n",
    "print(out3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'CudaNdarray([[ 1.  1.]\\n [ 1.  1.]\\n [ 1.  1.]])'\n",
      "[[ 12.  12.]\n",
      " [  9.   9.]\n",
      " [ 12.  12.]\n",
      " [ 12.  12.]]\n",
      "b'CudaNdarray([ 1.  1.  1.])'\n",
      "[[ 25.  25.  25.]\n",
      " [ 19.  19.  19.]\n",
      " [ 25.  25.  25.]\n",
      " [ 25.  25.  25.]]\n",
      "---------------------------------------------------\n",
      "[[ 25.  25.  25.]\n",
      " [ 19.  19.  19.]\n",
      " [ 25.  25.  25.]\n",
      " [ 25.  25.  25.]]\n",
      "[[ 0.33333334  0.33333334  0.33333334]\n",
      " [ 0.33333334  0.33333334  0.33333334]\n",
      " [ 0.33333334  0.33333334  0.33333334]\n",
      " [ 0.33333334  0.33333334  0.33333334]]\n",
      "[[ 3.  3.  2.]\n",
      " [ 1.  2.  3.]\n",
      " [ 4.  3.  1.]\n",
      " [ 2.  5.  1.]]\n",
      "---------------------------------------------------\n",
      "[[ 1.  6.  1.]\n",
      " [ 1.  3.  2.]\n",
      " [ 5.  2.  1.]\n",
      " [ 5.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(W.eval())\n",
    "print(out1.eval())\n",
    "print(vbias.eval())\n",
    "print( (T.dot(out1,W.T)+ vbias).eval())\n",
    "print('---------------------------------------------------')\n",
    "[out11,out12,out13] = sample_v_given_h(out1, b_sum)\n",
    "print(out11.eval())\n",
    "print(out12.eval())\n",
    "print(out13.eval())\n",
    "print('---------------------------------------------------')\n",
    "print(b.get_value())\n",
    "\n",
    "out12.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.  3.  3.]\n",
      "  [ 3.  3.  3.]\n",
      "  [ 3.  3.  3.]\n",
      "  [ 3.  3.  3.]]\n",
      "\n",
      " [[ 3.  3.  3.]\n",
      "  [ 3.  3.  3.]\n",
      "  [ 3.  3.  3.]\n",
      "  [ 3.  3.  3.]]]\n",
      "[[[ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.33333334  0.33333334  0.33333334]]\n",
      "\n",
      " [[ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.33333334  0.33333334  0.33333334]]]\n",
      "[[[ 3.  2.  3.]\n",
      "  [ 3.  2.  1.]\n",
      "  [ 4.  3.  1.]\n",
      "  [ 1.  5.  2.]]\n",
      "\n",
      " [[ 2.  3.  3.]\n",
      "  [ 0.  5.  1.]\n",
      "  [ 2.  3.  3.]\n",
      "  [ 3.  3.  2.]]]\n",
      "[[[ 12.  12.]\n",
      "  [  9.   9.]\n",
      "  [ 12.  12.]\n",
      "  [ 12.  12.]]\n",
      "\n",
      " [[ 12.  12.]\n",
      "  [  9.   9.]\n",
      "  [ 12.  12.]\n",
      "  [ 12.  12.]]]\n",
      "[[[ 0.9999938   0.9999938 ]\n",
      "  [ 0.99987662  0.99987662]\n",
      "  [ 0.9999938   0.9999938 ]\n",
      "  [ 0.9999938   0.9999938 ]]\n",
      "\n",
      " [[ 0.9999938   0.9999938 ]\n",
      "  [ 0.99987662  0.99987662]\n",
      "  [ 0.9999938   0.9999938 ]\n",
      "  [ 0.9999938   0.9999938 ]]]\n",
      "[[[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]\n",
      "\n",
      " [[ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]\n",
      "  [ 1.  1.]]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array( np.array([[1,6,1],[1,3,2],[5,2,1],[5,1,2]], dtype = theano.config.floatX) )\n",
    "output = hgv(b)\n",
    "[out_1,out_2,out_3,out_4,out_5,out_6] = output\n",
    "print(out_1)\n",
    "print(out_2)\n",
    "print(out_3)\n",
    "print(out_4)\n",
    "print(out_5)\n",
    "print(out_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def free_energy(v_sample, v_doc_len):\n",
    "    wx_b = T.dot(v_sample, W) + T.outer(v_doc_len, hbias)                      #---------------------------[edited]\n",
    "    vbias_term = T.dot(v_sample, vbias)\n",
    "    hidden_term = T.sum(T.log(1 + T.exp(wx_b)), axis=1)\n",
    "    return -hidden_term - vbias_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-30.000070571899414, dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.mean(free_energy(b,b_sum)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  4.  1.]\n",
      " [ 1.  3.  2.]\n",
      " [ 1.  3.  4.]\n",
      " [ 1.  4.  3.]]\n"
     ]
    }
   ],
   "source": [
    "a = theano_rng.multinomial(size=None, n=b.sum(axis=1), pvals=out_2[0], dtype=theano.config.floatX)\n",
    "print(a.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomFunction{multinomial_helper}.1"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_rng = np.random.RandomState(1234)\n",
    "np.asarray(np_rng.uniform(\n",
    "                    low=-4 * np.sqrt(6. / (5)),\n",
    "                    high=4 * np.sqrt(6. / (5)),\n",
    "                    size=(3, 4)\n",
    "                ), dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "#theano.sandbox.rng_mrg.MRG_RandomStreams(seed=12345).multinomial(size=None, n=b.sum(axis=1), pvals=out_2[0], dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "T.shared_randomstreams.RandomStreams(1234).multinomial(size=None, n=b.sum(axis=1), pvals=out_2[0], dtype=theano.config.floatX)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
